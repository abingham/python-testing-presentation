{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `unittest`\n",
    "**Testing with the standard library**\n",
    "\n",
    "docs.python.org/3/library/unittest.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Basic features\n",
    "\n",
    "* Test automation\n",
    "* Sharing of setup and shutdown code for tests\n",
    "* Aggregation of tests into collections\n",
    "* Independence of the tests from the reporting framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "* TestCase the basic unit of test organization\n",
    " * provides assertions\n",
    " * provides fixtures\n",
    " * Groups together related test functions\n",
    "* Test methods\n",
    "* assertions\n",
    " * equality, truth, is/not\n",
    " * contained\n",
    " * raises, logs, warns\n",
    " * comparison operators\n",
    " * list/set/etc. equality\n",
    "* fixtures\n",
    " * setUp/tearDown\n",
    " * setUpClass/tearDownClass\n",
    " * setUpModule/tearDownModule\n",
    "* test discovery\n",
    "* unittest.main()\n",
    "* test skipping\n",
    "* subtests\n",
    "* TestLoader\n",
    "* TestRunner\n",
    "* TestResult\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `unittest.TestCase`\n",
    "*The basic unit of test organization*\n",
    "\n",
    "* provides assertion methods\n",
    "* test and class fixtures\n",
    "* related test methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**To create a test**, subclass from `unittest.TestCase` and implement test methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "def run(test_case):\n",
    "    \"\"\"Run a test case and display basic results.\n",
    "    \"\"\"\n",
    "    runner = unittest.defaultTestLoader.loadTestsFromTestCase(Tests)\n",
    "    result = unittest.TestResult()\n",
    "    result = runner.run(result)\n",
    "    print('FAILURES: {}'.format(len(result.failures)))\n",
    "    print('ERROR: {}'.format(len(result.errors)))\n",
    "    print('TOTAL: {}'.format(result.testsRun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The simplest `TestCase` example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    pass\n",
    "\n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Not terribly exciting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Test methods start with \"test\"\n",
    "\n",
    "Actual testing occurs in `TestCase` methods that start with \"test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    def test_empty(self):\n",
    "        pass\n",
    "    \n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Still not very interesting, but we see that a test has been run!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assertions\n",
    "*Expressions of expectations*\n",
    "\n",
    "`TestCase` provides assertion methods that determine if tests pass or fail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    def test_always_passes(self):\n",
    "        self.assertTrue(True)\n",
    "        \n",
    "    def test_always_fails(self):\n",
    "        self.assertFalse(True)\n",
    "        \n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Common assertions\n",
    "\n",
    "| method name                 | checks               | | method name                | checks               |\n",
    "|-----------------------------|----------------------|-|----------------------------|----------------------|\n",
    "| assertEqual(a, b)           | a == b               | |assertIsNone(x)\t          | x is None            |\n",
    "| assertNotEqual(a, b)        | a != b               | |assertIsNotNone(x)\t\t  | x is not None        |\n",
    "| assertTrue(x)\t              | bool(x) is True      | |assertIn(a, b)\t\t      | a in b               |\n",
    "| assertFalse(x)              | bool(x) is False     | |assertNotIn(a, b)\t          | a not in b           |\n",
    "| assertIs(a, b)\t\t      | a is b               | |assertIsInstance(a, b)\t  | isinstance(a, b)     |\n",
    "| assertIsNot(a, b)\t\t      | a is not b           | |assertNotIsInstance(a, b)\t  | not isinstance(a, b) |\n",
    "\n",
    "See full details in the [`TestCase` documentation](https://docs.python.org/3/library/unittest.html#unittest.TestCase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Testing for exceptions\n",
    "`assertRaises` is a *context-manager* that checks for an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    def test_index_error(self):\n",
    "        with self.assertRaises(IndexError):\n",
    "            raise IndexError()\n",
    "            \n",
    "    def test_value_error(self):\n",
    "        with self.assertRaises(ValueError):\n",
    "            pass\n",
    "            \n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fixtures\n",
    "*Test set-up and clean-up*\n",
    "\n",
    "Code run at various times in the test run:\n",
    "\n",
    "| name                     | type            | when                         |\n",
    "|--------------------------|-----------------|------------------------------|\n",
    "| `TestCase.setUp`         | instance method | before each test method      |\n",
    "| `TestCase.tearDown`      | instance method | after each test method       |\n",
    "| `TestCase.setUpClass`    | class method    | before any methods run       |\n",
    "| `TestCase.tearDownClass` | class method    | after all methods run        |\n",
    "| `setUpModule`            | global function | before any methods in module |\n",
    "| `tearDownModule`         | global function | after all methods in module  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What are fixtures for?\n",
    "They ensure a known state for tests and clean up resources.\n",
    "\n",
    "* Create/clear database tables\n",
    "* Configure instance members\n",
    "* Create/delete temporary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls): print('set up class')\n",
    "        \n",
    "    @classmethod\n",
    "    def tearDownClass(cls): print('tear down class')\n",
    "        \n",
    "    def setUp(self): print('- set up')\n",
    "        \n",
    "    def tearDown(self): print('- tear down')\n",
    "        \n",
    "    def test_one(self): print('-- test one')\n",
    "    \n",
    "    def test_two(self): print('-- test two')\n",
    "    \n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Configuring member attributes\n",
    "\n",
    "`setUp()` is often used to assign to attributes used in tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.data = {'a': 2}\n",
    "        \n",
    "    def test_foo(self):\n",
    "        self.assertEqual(self.data['a'], 2)\n",
    "        self.data['a'] = 42\n",
    "        \n",
    "    def test_bar(self):\n",
    "        self.assertEqual(self.data['a'], 2)\n",
    "        self.data['a'] = 1337\n",
    "        \n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `unittest.main()`\n",
    "*Convenience function for running from the command line*\n",
    "\n",
    "```python\n",
    "import unittest\n",
    "\n",
    "\n",
    "class Tests(unittest.TestCase):\n",
    "    def test_foo(self):\n",
    "        self.assertEqual(1, 2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F\n",
      "======================================================================\n",
      "FAIL: test_foo (__main__.Tests)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sixtynorth/projects/python-testing-presentation/examples/unittest_main.py\", line 6, in test_foo\n",
      "    self.assertEqual(1, 2)\n",
      "AssertionError: 1 != 2\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
     ]
    }
   ],
   "source": [
    "%run examples/unittest_main.py"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "livereveal": {
   "theme": "white",
   "transition": "slide"
  },
  "name": "testing-in-python.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
