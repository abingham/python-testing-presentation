{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  # `unittest`\n",
    "**Testing with the standard library**\n",
    "\n",
    "[docs.python.org/3/library/unittest.html](http://docs.python.org/3/library/unittest.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Basic features\n",
    "\n",
    "* Test automation\n",
    "* Sharing of setup and shutdown code for tests\n",
    "* Aggregation of tests into collections\n",
    "* Independence of the tests from the reporting framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "* TestCase the basic unit of test organization\n",
    " * provides assertions\n",
    " * provides fixtures\n",
    " * Groups together related test functions\n",
    "* Test methods\n",
    "* assertions\n",
    " * equality, truth, is/not\n",
    " * contained\n",
    " * raises, logs, warns\n",
    " * comparison operators\n",
    " * list/set/etc. equality\n",
    "* fixtures\n",
    " * setUp/tearDown\n",
    " * setUpClass/tearDownClass\n",
    " * setUpModule/tearDownModule\n",
    "* test discovery\n",
    "* unittest.main()\n",
    "* test skipping\n",
    "* subtests\n",
    "* TestLoader\n",
    "* TestRunner\n",
    "* TestResult\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `unittest.TestCase`\n",
    "*The basic unit of test organization*\n",
    "\n",
    "* provides assertion methods\n",
    "* test and class fixtures\n",
    "* related test methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**To create a test**, subclass from `unittest.TestCase` and implement test methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# This sets up some utilities that we use later in the presentation\n",
    "import unittest\n",
    "\n",
    "def run(test_case):\n",
    "    \"\"\"Run a test case and display basic results.\n",
    "    \"\"\"\n",
    "    runner = unittest.defaultTestLoader.loadTestsFromTestCase(Tests)\n",
    "    result = unittest.TestResult()\n",
    "    result = runner.run(result)\n",
    "    print('FAILURES: {}'.format(len(result.failures)))\n",
    "    for f in result.failures:\n",
    "        print(f[1])\n",
    "    print('ERRORS: {}'.format(len(result.errors)))\n",
    "    for e in result.errors:\n",
    "        print(e[1])\n",
    "    print('SKIPPED: {}'.format(len(result.skipped)))\n",
    "    for s in result.skipped:\n",
    "        print(s[1])\n",
    "    print('TOTAL: {}'.format(result.testsRun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The simplest `TestCase` example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# This TestCase does nothing\n",
    "class Tests(unittest.TestCase):\n",
    "    pass\n",
    "\n",
    "# Running this will report zero tests.\n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Not terribly exciting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Test methods start with \"test\"\n",
    "\n",
    "Actual testing occurs in `TestCase` methods that start with \"test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    # test_ indicates a test to be run. This one does nothing.\n",
    "    def test_empty(self):\n",
    "        pass\n",
    "    \n",
    "    # So does just \"test\", but it's less Pythonic\n",
    "    def testNothing(self):\n",
    "        pass\n",
    "    \n",
    "    # This test isn't found because it doesn't start with test\n",
    "    def empty_test(self):\n",
    "        pass\n",
    "    \n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Still not very interesting, but we see that a test has been run!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assertions\n",
    "*Expressions of expectations*\n",
    "\n",
    "`TestCase` provides assertion methods that determine if tests pass or fail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    # This test passes trivially\n",
    "    def test_always_passes(self):\n",
    "        self.assertTrue(True)\n",
    "        \n",
    "    # This test fails trivially\n",
    "    def test_always_fails(self):\n",
    "        self.assertFalse(True)\n",
    "        \n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Common assertions\n",
    "\n",
    "| method name                 | checks               | | method name                | checks                 |\n",
    "|-----------------------------|----------------------|-|----------------------------|------------------------|\n",
    "| `assertEqual(a, b)`         | `a == b`             | | `assertIsNone(x)`\t        | `x is None`            |\n",
    "| `assertNotEqual(a, b)`      | `a != b`             | | `assertIsNotNone(x)`\t\t| `x is not None`        |\n",
    "| `assertTrue(x)`\t          | `bool(x) is True`    | | `assertIn(a, b)`\t\t    | `a in b`               |\n",
    "| `assertFalse(x)`            | `bool(x) is False`   | | `assertNotIn(a, b)`        | `a not in b`           |\n",
    "| `assertIs(a, b)`\t\t      | `a is b`             | |`assertIsInstance(a, b)`\t| `isinstance(a, b)`     |\n",
    "| `assertIsNot(a, b)`\t\t  | `a is not b`         | |`assertNotIsInstance(a, b)`\t| `not isinstance(a, b)` |\n",
    "\n",
    "See full details in the [`TestCase` documentation](https://docs.python.org/3/library/unittest.html#unittest.TestCase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Testing for exceptions\n",
    "`assertRaises` is a *context-manager* that checks for an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    # Verify that an IndexError is thrown in the test\n",
    "    def test_index_error(self):\n",
    "        with self.assertRaises(IndexError):\n",
    "            raise IndexError()\n",
    "            \n",
    "    def test_value_error(self):\n",
    "        # Verify that a ValueError is thrown in the test\n",
    "        with self.assertRaises(ValueError):\n",
    "            pass\n",
    "            \n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fixtures\n",
    "*Test set-up and clean-up*\n",
    "\n",
    "Code run at various times in the test run:\n",
    "\n",
    "| name                     | type            | when                         |\n",
    "|--------------------------|-----------------|------------------------------|\n",
    "| `TestCase.setUp`         | instance method | before each test method      |\n",
    "| `TestCase.tearDown`      | instance method | after each test method       |\n",
    "| `TestCase.setUpClass`    | class method    | before any methods run       |\n",
    "| `TestCase.tearDownClass` | class method    | after all methods run        |\n",
    "| `setUpModule`            | global function | before any methods in module |\n",
    "| `tearDownModule`         | global function | after all methods in module  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What are fixtures for?\n",
    "They ensure a known state for tests and clean up resources.\n",
    "\n",
    "* Create/clear database tables\n",
    "* Configure instance members\n",
    "* Create/delete temporary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    # This is run once before any of the tests in the TestCase\n",
    "    @classmethod\n",
    "    def setUpClass(cls): print('set up class')\n",
    "        \n",
    "    # This is run once after all of the tests in the TestCase have run\n",
    "    @classmethod\n",
    "    def tearDownClass(cls): print('tear down class')\n",
    "        \n",
    "    # This is run before *each* test in the TestCase\n",
    "    def setUp(self): print('- set up')\n",
    "        \n",
    "    # This is run after *each* test in the TestCase\n",
    "    def tearDown(self): print('- tear down')\n",
    "        \n",
    "    # A few demo tests\n",
    "    def test_one(self): print('-- test one')\n",
    "    def test_two(self): print('-- test two')\n",
    "    \n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Configuring member attributes\n",
    "\n",
    "`setUp()` is often used to assign to attributes used in tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # self.data will be set to this value before each test in the TestCase\n",
    "        self.data = {'a': 2}\n",
    "        \n",
    "    def test_foo(self):\n",
    "        # We can test the value of self.data\n",
    "        self.assertEqual(self.data['a'], 2)\n",
    "        \n",
    "        # Modifications to self.data will be reset by setUp()\n",
    "        self.data['a'] = 42\n",
    "        \n",
    "    def test_bar(self):\n",
    "        self.assertEqual(self.data['a'], 2)\n",
    "        self.data['a'] = 1337\n",
    "        \n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `unittest.main()`\n",
    "*Convenience function for running from the command line*\n",
    "\n",
    "```python\n",
    "import unittest\n",
    "\n",
    "\n",
    "class Tests(unittest.TestCase):\n",
    "    # This fails trivially\n",
    "    def test_foo(self):\n",
    "        self.assertEqual(1, 2)\n",
    "\n",
    "# This the idiomatic test for \"am I the top-level program\" in Python\n",
    "if __name__ == '__main__':\n",
    "    # If this is the top-level program, this scans for all TestCases and runs them.\n",
    "    unittest.main()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%run examples/unittest_main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Skipping tests with decorators\n",
    "*Use the decorators `skip()`, `skipIf`, and `skipUnless` to skip tests*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# This controls which tests run\n",
    "some_condition = True\n",
    "\n",
    "class Tests(unittest.TestCase):\n",
    "    @unittest.skip('This test never runs')\n",
    "    def test_no_run(self):\n",
    "        print('This will never execute in a test suite.')\n",
    "        \n",
    "    # We only run this test if our condition is False\n",
    "    @unittest.skipIf(some_condition == True, 'Condition is true')\n",
    "    def test_when_condition_is_false(self):\n",
    "        pass\n",
    "    \n",
    "    # We only run this test if our condition is True\n",
    "    @unittest.skipUnless(some_condition == True, 'Condition is false')\n",
    "    def test_when_condition_is_true(self):\n",
    "        pass\n",
    "    \n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Skipping tests from fixtures with `SkipTest`\n",
    "* Throw the `SkipTest` exception from `setUp()` to skip tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # We skip tests if a necessary resource is not available\n",
    "        raise unittest.SkipTest(\n",
    "            'Satellite uplink is not available right now.')\n",
    "        \n",
    "    # This test will only be run if the satellite uplink is available\n",
    "    def test_contact_satellite(self):\n",
    "        pass\n",
    "    \n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Allow failures with `expectedFailure`\n",
    "*`expectedFailure` allows a failing test to count as passing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    # The failing assertion in this test is not counted as a failure\n",
    "    @unittest.expectedFailure\n",
    "    def test_this_will_fail(self):\n",
    "        self.assertTrue(False)\n",
    "        \n",
    "run(Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parameterize tests with `TestCase.subTest`\n",
    "*Run the same test with multiple parameters, treating each as a separate test*\n",
    "*New in 3.4*\n",
    "\n",
    "This reduces boilerplate in certain situations since failure of one subtest does not prevent execution of other subtests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class Tests(unittest.TestCase):\n",
    "    def test_all_ascii(self):\n",
    "        for word in ['thread', 'tråd', 'island', 'øy']:\n",
    "            with self.subTest(word=word):\n",
    "                self.assertTrue(all(c in string.ascii_lowercase for c in word))\n",
    "            \n",
    "run(Tests)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "livereveal": {
   "theme": "white",
   "transition": "slide"
  },
  "name": "testing-in-python.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
